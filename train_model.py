# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10hfO_3m1saVa6CLo41AlgMeQZopv0Uz1
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Load datasets
tsunami_data = pd.read_csv("cleaned_tsunami_dataset.csv")
flood_data = pd.read_csv("cleaned_flood_dataset.csv")
earthquake_data = pd.read_csv("cleaned_earthquake_1995-2023.csv")

# Standardize column names
tsunami_data.rename(columns={'LATITUDE': 'latitude', 'LONGITUDE': 'longitude', 'EQ_MAGNITUDE': 'magnitude'}, inplace=True)
earthquake_data.rename(columns={'magnitude': 'magnitude', 'latitude': 'latitude', 'longitude': 'longitude', 'depth': 'depth'}, inplace=True)

# Fill missing values
tsunami_data['magnitude'].fillna(tsunami_data['magnitude'].mean(), inplace=True)
tsunami_data['depth'] = earthquake_data['depth'].mean()

# Select relevant features
tsunami_data = tsunami_data[['magnitude', 'depth', 'latitude', 'longitude']]
flood_data = flood_data[['floodprobability', 'monsoonintensity', 'urbanization', 'climatechange', 'drainagesystems']]
flood_data.rename(columns={'floodprobability': 'magnitude', 'monsoonintensity': 'depth', 'urbanization': 'latitude', 'climatechange': 'longitude'}, inplace=True)
earthquake_data = earthquake_data[['magnitude', 'depth', 'latitude', 'longitude']]

# Add target labels
tsunami_data['target'] = 'tsunami'
flood_data['target'] = 'flood'
earthquake_data['target'] = 'earthquake'

# Combine datasets
combined_data = pd.concat([tsunami_data, flood_data, earthquake_data], ignore_index=True)

# Define features (X) and target (y)
X = combined_data[['magnitude', 'depth', 'latitude', 'longitude']]
y = combined_data['target']

# Print feature names to verify consistency
print("Feature Names Used for Training:", X.columns.tolist())

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Save the trained model with feature names
joblib.dump((model, X.columns.tolist()), "disaster_model.pkl")

# Print results
print("Model trained successfully and saved as 'disaster_model.pkl'")